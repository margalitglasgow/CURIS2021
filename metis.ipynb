{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Imported Metis\n",
      "15\n",
      "4\n",
      "[(1, 2), (1, 3), (2, 3), (3, 'm')]\n"
     ]
    }
   ],
   "source": [
    "print(\"starting\")\n",
    "\n",
    "import networkx as nx\n",
    "import metis\n",
    "\n",
    "print(\"Imported Metis\")\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(1) \n",
    "G.add_nodes_from([2, 3])\n",
    "H = nx.path_graph(10)\n",
    "G.add_nodes_from(H)\n",
    "G.add_edge(1, 2)\n",
    "e = (2, 3)\n",
    "G.add_edge(*e)  # unpack edge tuple*\n",
    "G.add_edges_from([(1, 2), (1, 3)])\n",
    "G.add_node(1)\n",
    "G.add_edge(1, 2)\n",
    "G.add_node(\"spam\")        # adds node \"spam\"\n",
    "G.add_nodes_from(\"spam\")  # adds 4 nodes: 's', 'p', 'a', 'm'\n",
    "G.add_edge(3, 'm')\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "print(list(G.edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 100 nodes and 423 edges\n"
     ]
    }
   ],
   "source": [
    "G = nx.erdos_renyi_graph(100, 0.0808080808)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METIS_Graph(nvtxs=c_int(100), ncon=c_int(1), xadj=<metis.c_int_Array_101 object at 0x7ff721b44440>, adjncy=<metis.c_int_Array_846 object at 0x7ff721edec40>, vwgt=None, vsize=None, adjwgt=None)\n"
     ]
    }
   ],
   "source": [
    "metisG = metis.networkx_to_metis(G)\n",
    "print(metisG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_budget = 400\n",
    "partition = 1\n",
    "edgecuts = 0\n",
    "edgecut_budget = []\n",
    "Y2 = []\n",
    "print(\"About to start while loop\")\n",
    "while (edgecuts < max_budget):\n",
    "      (edgecuts, parts) = metis.part_graph(metisG, partition)\n",
    "      print(\"Did metis part\")\n",
    "      if (edgecuts < max_budget):\n",
    "            print(partition)\n",
    "            edgecut_budget.append(edgecuts)\n",
    "      cluster_sizes = {}\n",
    "      for num in parts:\n",
    "            if num not in cluster_sizes:\n",
    "                  cluster_sizes[num] = 0\n",
    "            cluster_sizes[num] += 1\n",
    "      max = 0\n",
    "      for num in cluster_sizes:\n",
    "            if cluster_sizes[num] > max:\n",
    "                  max = cluster_sizes[num]\n",
    "      Y2.append(max)\n",
    "      partition += 1\n",
    "    \n",
    "plt.plot(budgets, Y, label=\"Spectral Cut-Based Edge Removal\")\n",
    "plt.plot(edgecut_budget, Y2, label=\"Spectral Cut-Based Edge Removal\")\n",
    "\n",
    "plt.xlabel(\"Edge Budget\")\n",
    "plt.ylabel(\"Infection Size\")\n",
    "plt.title(\"Erdos Renyi (100 nodes, 400 edges)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.petersen_graph()\n",
    "subax1 = plt.subplot(121)\n",
    "nx.draw(G, with_labels=True, font_weight='bold')\n",
    "subax2 = plt.subplot(122)\n",
    "nx.draw_shell(G, nlist=[range(5, 10), range(5)], with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "import metis\n",
    "import networkx\n",
    "import pydot\n",
    "\n",
    "graph = nx.erdos_renyi_graph(100, 0.0808080808, 1)\n",
    "print(graph)\n",
    "G = metis.networkx_to_metis(graph)\n",
    "(edgecuts, parts) = metis.part_graph(G, 3)\n",
    "print((edgecuts, parts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.linalg as la\n",
    "\n",
    "def tuples_to_dict(graph, N):\n",
    "  graph_dict = {}\n",
    "  for i in range(N):\n",
    "    graph_dict[i] = []\n",
    "  for edge in graph:\n",
    "    graph_dict[edge[0]].append(edge[1])\n",
    "  return graph_dict\n",
    "\n",
    "def find_degrees(graph_dict, node_list):\n",
    "  degs = []\n",
    "  for i in node_list:\n",
    "    degs.append(len(graph_dict[i]))\n",
    "  return degs\n",
    "\n",
    "def node_index(node, node_list):\n",
    "  for index in range(len(node_list)):\n",
    "    if (node_list[index] == node):\n",
    "      return index\n",
    "\n",
    "def graph_to_laplacian(graph_dict, node_list):\n",
    "  # graph_dict = tuples_to_dict(graph, node_list)\n",
    "  D = find_degrees(graph_dict, node_list)\n",
    "  L = np.diag(D)\n",
    "  for node in graph_dict:\n",
    "      for neighbor in graph_dict[node]:\n",
    "        L[node_index(node, node_list)][node_index(neighbor, node_list)] = -1\n",
    "        L[node_index(neighbor, node_list)][node_index(node, node_list)] = -1\n",
    "  return L\n",
    "\n",
    "def graph_to_A(graph_dict, node_list):\n",
    "  # graph_dict = tuples_to_dict(graph, node_list)\n",
    "  N = len(graph_dict)\n",
    "  A = np.zeros((N, N))\n",
    "  for node in graph_dict:\n",
    "      for neighbor in graph_dict[node]:\n",
    "        A[node_index(node, node_list)][node_index(neighbor, node_list)] = 1\n",
    "        A[node_index(neighbor, node_list)][node_index(node, node_list)] = 1\n",
    "  return A\n",
    "\n",
    "def calculate_M(node_list, N):\n",
    "  M = np.zeros((N, N))\n",
    "  for s in node_list:\n",
    "    for t in node_list:\n",
    "      if s != t:\n",
    "        e_s = np.zeros(N)\n",
    "        e_s[s] = 1\n",
    "        e_t = np.zeros(N)\n",
    "        e_t[t] = 1\n",
    "        M += (e_s - e_t) @ (e_s - e_t).T\n",
    "  return M\n",
    "\n",
    "def dict_to_tuples(graph_dict):\n",
    "  graph = []\n",
    "  for u in graph_dict:\n",
    "    for v in graph_dict[u]:\n",
    "      graph.append([u,v])\n",
    "  return graph\n",
    "\n",
    "def effective_edge_resistance(graph_dict, N, edge_budget):\n",
    "  edges_removed = 0\n",
    "  node_list = [i for i in range(N)]\n",
    "  M = calculate_M(node_list, N)\n",
    "  while edges_removed < edge_budget:\n",
    "    L = graph_to_laplacian(graph_dict, node_list)\n",
    "    L_inv = np.linalg.pinv(L)\n",
    "    edge_resistances = {}\n",
    "    for u in graph_dict:\n",
    "      e_u = np.zeros(N)\n",
    "      e_u[u] = 1\n",
    "      for v in graph_dict[u]:\n",
    "        e_v = np.zeros(N)\n",
    "        e_v[v] = 1\n",
    "        edge_resistances[(u,v)] = (e_u - e_v).T @ L_inv @ M @ L_inv @ (e_u - e_v)\n",
    "    # print(len(edge_resistances))\n",
    "    removed_edge = max(edge_resistances, key=edge_resistances.get)\n",
    "    graph_dict[removed_edge[0]].remove(removed_edge[1])\n",
    "    graph_dict[removed_edge[1]].remove(removed_edge[0])\n",
    "    edges_removed += 1\n",
    "  \n",
    "  return graph_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percolation(neighbors_per_node, transmissionRate, recoveryRate):\n",
    "    newGraph = []\n",
    "    for node in neighbors_per_node:\n",
    "        recoveryTime = np.random.exponential(1/recoveryRate)\n",
    "        for neighbor in neighbors_per_node[node]:\n",
    "            transmissionTime = np.random.exponential(1/transmissionRate)\n",
    "            if (transmissionTime <= recoveryTime):\n",
    "                newGraph.append([node, neighbor])\n",
    "    return newGraph  \n",
    "\n",
    "def find_connected_nodes(node, graph_dict, connected_component):\n",
    "  if node not in connected_component:\n",
    "    connected_component.append(node)\n",
    "  for neighbor in graph_dict[node]:\n",
    "    if neighbor not in connected_component:\n",
    "      find_connected_nodes(neighbor, graph_dict, connected_component)\n",
    "\n",
    "def find_entire_connection(infected_nodes, neighbors_per_node):\n",
    "  connected_nodes = []\n",
    "  for node in infected_nodes:\n",
    "    find_connected_nodes(node, neighbors_per_node, connected_nodes)\n",
    "  return connected_nodes\n",
    "\n",
    "def calculateFinalInfection(graph_dict, N, numOfTrials, transmissionRate, recoveryRate):\n",
    "  num_infected = []\n",
    "  for i in range(numOfTrials):\n",
    "    # print(i)\n",
    "    graph = percolation(graph_dict, transmissionRate, recoveryRate)\n",
    "    neighbors_per_node = tuples_to_dict(graph, N)\n",
    "    infected_nodes = find_entire_connection(random.sample([i for i in range(0, N)], 1), neighbors_per_node)\n",
    "    num_infected.append(len(infected_nodes))\n",
    "  return np.mean(num_infected)\n",
    "\n",
    "def erdos_renyi_graph(N, M):\n",
    "  graph = []\n",
    "  node_list = [i for i in range(N)]\n",
    "  numEdges = 0\n",
    "  while numEdges < M:\n",
    "    edge = random.sample(node_list, 2)\n",
    "    edge2 = [edge[1], edge[0]]\n",
    "    if edge not in graph:\n",
    "      numEdges += 1\n",
    "      graph.append(edge)\n",
    "      graph.append(edge2)\n",
    "  return graph\n",
    "\n",
    "def config_model2(deg_dist, n):\n",
    "  node_list = np.arange(n)\n",
    "  degreeOfNodes = {}\n",
    "  for key in deg_dist:\n",
    "    num_nodes = int(round(deg_dist[key]*n))\n",
    "    nodes = node_list[:num_nodes]\n",
    "    for node in nodes:\n",
    "      degreeOfNodes[node] = key\n",
    "    node_list = node_list[num_nodes:]\n",
    "  sum_degs = 0\n",
    "  for key in deg_dist:\n",
    "    sum_degs += key*n*deg_dist[key]\n",
    "  numedges = sum_degs/2\n",
    "  half_edges = []\n",
    "  for node in degreeOfNodes:\n",
    "    deg = degreeOfNodes[node]\n",
    "    for i in range(deg):\n",
    "      half_edges.append(node)\n",
    "  graph = []\n",
    "  while half_edges != []:\n",
    "    node1 = np.random.choice(half_edges)\n",
    "    node2 = np.random.choice(half_edges)\n",
    "\n",
    "    if (node1 != node2 and [node1, node2] not in graph):\n",
    "      graph.append([node1, node2])\n",
    "      graph.append([node2, node1])\n",
    "      half_edges.remove(node1)\n",
    "      half_edges.remove(node2)\n",
    "  return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutting off 49 nodes with 137.0 edges out of 200\n",
      "({0: [40, 83, 70, 50, 84, 54, 41], 1: [23, 97, 17, 20, 73, 82, 6], 2: [76, 4, 30, 92, 46, 67], 3: [69, 28, 67], 4: [84, 2, 57], 5: [51, 37, 43, 6], 6: [51, 68, 58, 13, 1, 5, 56], 7: [], 8: [27, 12, 50, 71], 9: [67, 70, 72, 40], 10: [], 11: [], 12: [61, 8, 63, 60], 13: [88, 56, 82, 6, 33, 16], 14: [50, 28, 25], 15: [52, 22, 94, 73], 16: [64, 20, 43, 81, 91, 88, 32, 35, 38, 13], 17: [1, 91, 93, 68, 39, 58], 18: [39, 91, 43, 78, 23], 19: [], 20: [16, 78, 94, 1, 37, 52], 21: [], 22: [62, 68, 15, 89, 51], 23: [62, 1, 91, 97, 35, 36, 73, 18], 24: [], 25: [27, 96, 90, 14], 26: [], 27: [25, 90, 8, 84], 28: [54, 3, 30, 14, 69, 65], 29: [95, 40], 30: [96, 60, 28, 57, 2], 31: [], 32: [77, 16, 33, 68], 33: [58, 64, 91, 77, 51, 88, 37, 32, 13], 34: [51, 62, 78], 35: [23, 88, 16], 36: [23, 56, 38], 37: [86, 56, 5, 91, 20, 33], 38: [77, 58, 78, 86, 75, 36, 16], 39: [97, 18, 17], 40: [0, 29, 9], 41: [92, 0], 42: [], 43: [16, 78, 18, 5], 44: [], 45: [87, 90], 46: [83, 54, 85, 2, 79], 47: [], 48: [55, 57, 63, 67, 96], 49: [], 50: [63, 14, 55, 0, 8, 60, 83, 87], 51: [6, 77, 5, 52, 34, 22, 33, 97], 52: [15, 73, 51, 82, 20, 81], 53: [60, 83, 69, 71], 54: [28, 46, 0], 55: [48, 67, 50], 56: [37, 36, 13, 86, 75, 68, 6], 57: [90, 48, 30, 4], 58: [33, 38, 93, 6, 78, 17], 59: [], 60: [90, 53, 30, 50, 12], 61: [12, 67, 70], 62: [23, 22, 34, 68], 63: [50, 48, 69, 96, 87, 12, 70], 64: [16, 78, 77, 33], 65: [79, 69, 28], 66: [], 67: [9, 55, 61, 87, 48, 3, 71, 2], 68: [6, 22, 17, 56, 97, 32, 62], 69: [3, 63, 53, 83, 28, 70, 65], 70: [72, 0, 9, 61, 63, 69], 71: [87, 67, 53, 8], 72: [92, 70, 95, 85, 76, 9], 73: [52, 1, 89, 23, 15], 74: [], 75: [78, 56, 38], 76: [96, 2, 92, 72], 77: [38, 51, 64, 32, 33], 78: [20, 75, 43, 64, 38, 58, 34, 18], 79: [65, 85, 46], 80: [], 81: [16, 89, 52, 97], 82: [1, 52, 13], 83: [46, 53, 0, 69, 96, 50], 84: [4, 0, 27], 85: [72, 90, 46, 79], 86: [88, 37, 38, 56, 89], 87: [71, 45, 67, 63, 50], 88: [86, 13, 16, 35, 33], 89: [86, 73, 22, 81], 90: [60, 27, 57, 85, 25, 45], 91: [23, 37, 17, 18, 16, 33], 92: [72, 76, 41, 95, 2], 93: [58, 17], 94: [20, 97, 15], 95: [29, 72, 92], 96: [76, 30, 25, 63, 83, 48], 97: [39, 1, 23, 94, 51, 81, 68], 98: [], 99: []}, 137.0)\n"
     ]
    }
   ],
   "source": [
    "import heapq as hpq\n",
    "import random\n",
    "def random_edge_removal(graph, edge_budget):\n",
    "  edges = random.sample(graph, edge_budget)\n",
    "  # print (edges)\n",
    "  all_edges = []\n",
    "  for edge in edges:\n",
    "    if edge not in all_edges:\n",
    "      all_edges.append(edge)\n",
    "      all_edges.append([edge[1], edge[0]])\n",
    "    # if [edge[1], edge[0]] not in all_edges:\n",
    "      # all_edges.append([edge[1], edge[0]])\n",
    "  print (len(all_edges))\n",
    "  new_graph = []\n",
    "  for edge in graph:\n",
    "    if edge not in all_edges:\n",
    "      new_graph.append(edge)\n",
    "  return new_graph\n",
    "\n",
    "def tuples_to_dict(graph, N):\n",
    "  graph_dict = {}\n",
    "  for i in range(N):\n",
    "    graph_dict[i] = []\n",
    "  for edge in graph:\n",
    "    graph_dict[edge[0]].append(edge[1])\n",
    "  return graph_dict\n",
    "\n",
    "# When I look into the toal degree of an edge from both side,\n",
    "# and remove edges with the highest degree,\n",
    "# this is not necessarily \"proportional\" I think\n",
    "# it just cuts down the edges with extreme degrees\n",
    "def highest_degree_edge_removal(graph_dict, edge_budget):\n",
    "  degEdgeDict = {}\n",
    "  for edge in graph:\n",
    "    degEdgeDict[edge] = len(graph_dict[edge[0]]) + len(graph_dict[edge[0]]) - 2\n",
    "  i = 0\n",
    "  edges_to_remove = []\n",
    "  while (i < edge_budget):\n",
    "    edge1 = max(degEdgeDict, key=degEdgeDict.get)\n",
    "    degEdgeDict[edge1] -= 1\n",
    "    edge2 = [edge1[1], edge1[0]]\n",
    "    degEdgeDict[edge2] -= 1\n",
    "    edges_to_remove.append(edge1)\n",
    "    edges_to_remove.append(edge2)\n",
    "    i += 1\n",
    "  new_graph = []\n",
    "  for edge in graph:\n",
    "    if edge != edges_to_remove:\n",
    "      new_graph.append(edge)\n",
    "  return tuples_to_dict(new_graph)\n",
    "\n",
    "def dict_to_tuples(graph_dict):\n",
    "  graph = []\n",
    "  for u in graph_dict:\n",
    "    for v in graph_dict[u]:\n",
    "      graph.append([u,v])\n",
    "  return graph\n",
    "\n",
    "# the only way I could remove the edges was to remove half edges, because when I remove a full edge,\n",
    "# that affects the degree proprotion of the other side too – I don't know how to do this\n",
    "def degree_proportional_half_edge_removal(graph_dict, edge_budget):\n",
    "  degDict = {}\n",
    "  sum = 0\n",
    "  for node in graph_dict:\n",
    "    degDict[node] = len(graph_dict[node])\n",
    "    sum += len(graph_dict[node])\n",
    "  new_graph_dict = {}\n",
    "  for node in graph_dict:\n",
    "    # edge budget shoulbe multiplied by 2 to compensate for half edge removal\n",
    "    num = round((degDict[node] / sum) * 2 * edge_budget) # gives the number of edges to remove from this node\n",
    "    new_graph_dict[node] = random.sample(graph_dict[node], len(graph_dict[node]) - sum) \n",
    "    # len(graph_dict[node]) - sum is the number of remaning edges of this node after removal\n",
    "  return new_graph_dict\n",
    "\n",
    "def cut_size(A, left, right):\n",
    "  size = np.sum(A[left].T[right])\n",
    "  return size\n",
    "\n",
    "# Makes single largest cut in graph (doesn't use full budget)\n",
    "def biggest_cut_edge_removal(graph_dict, edge_budget):\n",
    "  N = len(graph_dict)\n",
    "  L = graph_to_laplacian(graph_dict, [i for i in range(N)])\n",
    "  A = graph_to_A(graph_dict, [i for i in range(N)])\n",
    "  results = la.eig(L)\n",
    "  eigvalues = results[0]\n",
    "  eigvectors = results[1]\n",
    "  idx = eigvalues.argsort()[::-1]\n",
    "  eigvectors = eigvectors[:,idx]  \n",
    "  second_smallest_vec = eigvectors[:, -2]\n",
    "  vec = second_smallest_vec.T\n",
    "  ids = vec.argsort()[::-1]\n",
    "  best_left = []\n",
    "  best_right = [i for i in range(N)]\n",
    "  best_cut = 0\n",
    "\n",
    "  for i in range(int(N/2)):\n",
    "    left = ids[:i]\n",
    "    right = ids[i:]\n",
    "    cut = cut_size(A, left, right)\n",
    "    if cut > edge_budget:\n",
    "      break\n",
    "    best_cut = cut\n",
    "    best_left = left\n",
    "    best_right = right\n",
    "  print(\"Cutting off %s nodes with %s edges out of %s\" % (i, best_cut, edge_budget))\n",
    "\n",
    "  new_graph = {}\n",
    "  for i in range(N):\n",
    "    new_graph[i] = []\n",
    "    for edge_end in graph_dict[i]:\n",
    "      if i in best_left and edge_end in best_left:\n",
    "        new_graph[i].append(edge_end)\n",
    "      elif i in best_right and edge_end in best_right:\n",
    "        new_graph[i].append(edge_end)\n",
    "  \n",
    "\n",
    "  return new_graph, best_cut\n",
    "\n",
    "\n",
    "def biggest_cut_edge_removal_recursive(graph_dict, edge_budget, node_list, components):\n",
    "  N = len(graph_dict)\n",
    "  \n",
    "  # print (graph_dict)\n",
    "\n",
    "  L = graph_to_laplacian(graph_dict, node_list)\n",
    "  A = graph_to_A(graph_dict, node_list)\n",
    "  results = la.eig(L)\n",
    "  eigvalues = results[0]\n",
    "  eigvectors = results[1]\n",
    "  idx = eigvalues.argsort()[::-1]\n",
    "  eigvectors = eigvectors[:,idx]  \n",
    "  second_smallest_vec = eigvectors[:, -2]\n",
    "  vec = second_smallest_vec.T\n",
    "  ids = vec.argsort()[::-1]\n",
    "  best_left = []\n",
    "  best_right = node_list\n",
    "  best_cut = 0\n",
    "\n",
    "  for i in range(int(N/2)):\n",
    "    left = []\n",
    "    for id in ids[:i]:\n",
    "      left.append(node_list[id])\n",
    "    right = []\n",
    "    for id in ids[i:]:\n",
    "      right.append(node_list[id])\n",
    "    # print (left)\n",
    "    # print (right)\n",
    "    cut = cut_size(A, ids[:i], ids[i:])\n",
    "    if cut > edge_budget:\n",
    "      break\n",
    "    best_cut = cut\n",
    "    best_left = left\n",
    "    best_right = right\n",
    "  print(\"Cutting off %s nodes with %s edges out of %s\" % (i, best_cut, edge_budget))\n",
    "\n",
    "  left_graph = {}\n",
    "  right_graph = {}\n",
    "  for i in node_list:\n",
    "    for edge_end in graph_dict[i]:\n",
    "      if i in best_left and edge_end in best_left:\n",
    "        if i not in left_graph:\n",
    "          left_graph[i] = []\n",
    "        left_graph[i].append(edge_end)\n",
    "      elif i in best_right and edge_end in best_right:\n",
    "        if i not in right_graph:\n",
    "          right_graph[i] = []\n",
    "        right_graph[i].append(edge_end)\n",
    "\n",
    "  hpq.heappush(components, (-len(right_graph), random.random() , right_graph))\n",
    "  \n",
    "  hpq.heappush(components, (-len(left_graph), random.random(), left_graph))\n",
    "\n",
    "\n",
    "  if edge_budget > best_cut and len(best_left) > 0:\n",
    "    component = hpq.heappop(components)[2]\n",
    "    c_nodes = []\n",
    "    for node in component:\n",
    "      c_nodes.append(node)\n",
    "    new_component, best_cut1 = biggest_cut_edge_removal_recursive(component, edge_budget - best_cut, c_nodes, components)\n",
    "  # print (graph_dict)\n",
    "  new_graph = left_graph.copy()\n",
    "  new_graph.update(right_graph)\n",
    "\n",
    "  return new_graph, best_cut\n",
    "\n",
    "def merge(components):\n",
    "  first = hpq.heappop(components)\n",
    "  new_graph = first[2]\n",
    "  for component in components:\n",
    "    new_graph.update(component[2])\n",
    "  return new_graph\n",
    "\n",
    "\n",
    "def biggest_cut_edge_removal_greedy(graph_dict, edge_budget):\n",
    "  N = len(graph_dict)\n",
    "  L = graph_to_laplacian(graph_dict, [i for i in range(N)])\n",
    "  A = graph_to_A(graph_dict, [i for i in range(N)])\n",
    "  results = la.eig(L)\n",
    "  eigvalues = results[0]\n",
    "  eigvectors = results[1]\n",
    "  idx = eigvalues.argsort()[::-1]\n",
    "  eigvectors = eigvectors[:,idx]  \n",
    "  second_smallest_vec = eigvectors[:, -2]\n",
    "  vec = second_smallest_vec.T\n",
    "  ids = vec.argsort()[::-1]\n",
    "  best_left = []\n",
    "  best_right = [i for i in range(N)]\n",
    "  best_cut = 0\n",
    "\n",
    "  for i in range(int(N/2)):\n",
    "    left = ids[:i]\n",
    "    right = ids[i:]\n",
    "    cut = cut_size(A, left, right)\n",
    "    if cut > edge_budget:\n",
    "      break\n",
    "    best_cut = cut\n",
    "    best_left = left\n",
    "    best_right = right\n",
    "  print(\"Cutting off %s nodes with %s edges out of %s\" % (i, best_cut, edge_budget))\n",
    "\n",
    "  new_graph = {}\n",
    "  for i in range(N):\n",
    "    new_graph[i] = []\n",
    "    for edge_end in graph_dict[i]:\n",
    "      if i in best_left and edge_end in best_left:\n",
    "        new_graph[i].append(edge_end)\n",
    "      elif i in best_right and edge_end in best_right:\n",
    "        new_graph[i].append(edge_end)\n",
    "  # print (new_graph)\n",
    "  if edge_budget > best_cut:\n",
    "    new_graph = effective_edge_resistance(new_graph, N, edge_budget - best_cut)\n",
    "\n",
    "\n",
    "  return new_graph, best_cut\n",
    "\n",
    "graph = erdos_renyi_graph(100, 400)\n",
    "graph_dict = tuples_to_dict(graph, 100)\n",
    "\n",
    "components = []\n",
    "# components.heappush(-len(graph_dict), graph_dict)\n",
    "# biggest_cut_edge_removal_recursive(graph_dict, 50, [i for i in range(10)], components)\n",
    "graph_dict = biggest_cut_edge_removal_greedy(graph_dict, 200)\n",
    "print (graph_dict)\n",
    "# print (merge(components))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Cutting off 3 nodes with 5.0 edges out of 10\n",
      "2\n",
      "Cutting off 5 nodes with 17.0 edges out of 20\n",
      "3\n",
      "Cutting off 6 nodes with 25.0 edges out of 30\n",
      "4\n",
      "Cutting off 8 nodes with 38.0 edges out of 40\n",
      "5\n",
      "Cutting off 9 nodes with 45.0 edges out of 50\n",
      "6\n",
      "Cutting off 11 nodes with 60.0 edges out of 60\n",
      "7\n",
      "Cutting off 13 nodes with 65.0 edges out of 70\n",
      "8\n",
      "Cutting off 15 nodes with 75.0 edges out of 80\n",
      "9\n",
      "Cutting off 17 nodes with 90.0 edges out of 90\n",
      "10\n",
      "Cutting off 21 nodes with 99.0 edges out of 100\n",
      "11\n",
      "Cutting off 23 nodes with 108.0 edges out of 110\n",
      "12\n",
      "Cutting off 31 nodes with 119.0 edges out of 120\n",
      "13\n",
      "Cutting off 34 nodes with 126.0 edges out of 130\n",
      "14\n",
      "Cutting off 39 nodes with 137.0 edges out of 140\n",
      "15\n",
      "Cutting off 49 nodes with 139.0 edges out of 150\n",
      "16\n",
      "Cutting off 49 nodes with 139.0 edges out of 160\n",
      "17\n",
      "Cutting off 49 nodes with 139.0 edges out of 170\n",
      "18\n",
      "Cutting off 49 nodes with 139.0 edges out of 180\n",
      "19\n",
      "Cutting off 49 nodes with 139.0 edges out of 190\n",
      "20\n",
      "Cutting off 49 nodes with 139.0 edges out of 200\n",
      "21\n",
      "Cutting off 49 nodes with 139.0 edges out of 210\n",
      "22\n",
      "Cutting off 49 nodes with 139.0 edges out of 220\n",
      "23\n",
      "Cutting off 49 nodes with 139.0 edges out of 230\n",
      "24\n",
      "Cutting off 49 nodes with 139.0 edges out of 240\n",
      "25\n",
      "Cutting off 49 nodes with 139.0 edges out of 250\n",
      "26\n",
      "Cutting off 49 nodes with 139.0 edges out of 260\n",
      "27\n",
      "Cutting off 49 nodes with 139.0 edges out of 270\n",
      "28\n",
      "Cutting off 49 nodes with 139.0 edges out of 280\n",
      "29\n",
      "Cutting off 49 nodes with 139.0 edges out of 290\n",
      "30\n",
      "Cutting off 49 nodes with 139.0 edges out of 300\n",
      "31\n",
      "Cutting off 49 nodes with 139.0 edges out of 310\n",
      "32\n",
      "Cutting off 49 nodes with 139.0 edges out of 320\n",
      "33\n",
      "Cutting off 49 nodes with 139.0 edges out of 330\n",
      "34\n",
      "Cutting off 49 nodes with 139.0 edges out of 340\n",
      "35\n",
      "Cutting off 49 nodes with 139.0 edges out of 350\n",
      "36\n",
      "Cutting off 49 nodes with 139.0 edges out of 360\n",
      "37\n",
      "Cutting off 49 nodes with 139.0 edges out of 370\n",
      "38\n",
      "Cutting off 49 nodes with 139.0 edges out of 380\n",
      "39\n",
      "Cutting off 49 nodes with 139.0 edges out of 390\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import metis\n",
    "import pydot\n",
    "\n",
    "N = 100\n",
    "M = 400\n",
    "graph = erdos_renyi_graph(N, M)\n",
    "\n",
    "original_graph = tuples_to_dict(graph, N)\n",
    "budgets = []\n",
    "numOfTrials = 200\n",
    "transmissionRate = 0.9\n",
    "recoveryRate = 0.1\n",
    "Y = []\n",
    "increment = 10\n",
    "for i in range(1,40):\n",
    "  print (i)\n",
    "  budgets.append(increment*i)\n",
    "  graph_dict_cut = biggest_cut_edge_removal_greedy(original_graph, budgets[-1])[0]\n",
    "  Y.append(calculateFinalInfection(graph_dict_cut, N, numOfTrials, transmissionRate, recoveryRate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:301180)",
      "at w.execute (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:300551)",
      "at w.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:296215)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310950)",
      "at async t.CellExecutionQueue.start (/Users/senemisik/.vscode/extensions/ms-toolsai.jupyter-2021.9.1101343141/out/client/extension.js:52:310490)"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import metis\n",
    "\n",
    "G = nx.erdos_renyi_graph(100, 0.0808080808, 1)\n",
    "print(G)\n",
    "metisG = metis.networkx_to_metis(G)\n",
    "max_budget = 400\n",
    "partition = 1\n",
    "edgecuts = 0\n",
    "edgecut_budget = []\n",
    "Y2 = []\n",
    "while (edgecuts < max_budget):\n",
    "  (edgecuts, parts) = metis.part_graph(metisG, partition)\n",
    "  if (edgecuts < max_budget):\n",
    "    print(partition)\n",
    "    edgecut_budget.append(edgecuts)\n",
    "    cluster_sizes = {}\n",
    "    for num in parts:\n",
    "      if num not in cluster_sizes:\n",
    "        cluster_sizes[num] = 0\n",
    "      cluster_sizes[num] += 1\n",
    "    max = 0\n",
    "    for num in cluster_sizes:\n",
    "      if cluster_sizes[num] > max:\n",
    "        max = cluster_sizes[num]\n",
    "    Y2.append(max)\n",
    "  partition += 1\n",
    "    \n",
    "plt.plot(budgets, Y, label=\"Spectral Cut-Based Edge Removal\")\n",
    "plt.plot(edgecut_budget, Y2, label=\"Spectral Cut-Based Edge Removal\")\n",
    "\n",
    "plt.xlabel(\"Edge Budget\")\n",
    "plt.ylabel(\"Infection Size\")\n",
    "plt.title(\"Erdos Renyi (100 nodes, 400 edges)\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
